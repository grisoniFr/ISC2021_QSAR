<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN" "http://www.w3.org/TR/html4/strict.dtd">
<html>
<head>
<title>Classification toolbox for MATLAB</title>
<meta http-equiv="content-type" content="text/html; charset=iso-8859-1">
<meta name="generator" content="HAPedit 3.0">

<link href = "style_structure.css" rel="stylesheet" type="text/css">
<link href = "style_text.css" rel="stylesheet" type="text/css">
<link href = "style_tables.css" rel="stylesheet" type="text/css">

</head>
<body>
<div id="container">
<a name="top"></a>

    <div id="header">
		<iframe src="header.htm" width="740" height="60" scrolling="no" frameborder="0">
  			no i_frames allowed :: change browser
	  	</iframe>
    </div>

    <div id="content">

		<table width="740" border="0" cellpadding="0" cellspacing="0">
  		<tr>
		<td width="150" valign="top">
		
		<iframe src="menu_lateral.htm" width="135" height="360" scrolling="no" frameborder="0">
  			no i_frames allowed :: change browser
	  	</iframe>
		
		</td>

    	<td valign="top">

		  <div align="justify">
		    <div id="tab_duo_contenitor" class="text">
		    <span class="title_page">Using the GUI -&gt; calculate menu</span> 		
		    <BR>
		    <BR>
    
		<div id="tab_duo_text">
		      <div id="tab_space_lateral"><a href="#sub_1" class="lnk_text">Validation procedures</a></div>
			  <div id="tab_space_lateral"><a href="#sub_1a" class="lnk_text">Discriminant Analysis (DA)</a></div>
		      <div id="tab_space_lateral"><a href="#sub_2" class="lnk_text">Discriminant Analysis coupled with Principal Component Analysis (PCA-DA) </a> </div>
			  <div id="tab_space_lateral"><a href="#sub_3" class="lnk_text">Partial Least Square - Discriminant Analysis (PLSDA) </a></div>
		      <div id="tab_space_lateral"><a href="#sub_4" class="lnk_text">Classification Trees (CART)</a></div>	  
			  <div id="tab_space_lateral"><a href="#sub_5" class="lnk_text">K-Nearest Neighbors (kNN)</a></div>
			  <div id="tab_space_lateral"><a href="#sub_5a" class="lnk_text">Potential Functions (Kernel Density Estimators)</a></div>
			  <div id="tab_space_lateral"><a href="#sub_5b" class="lnk_text">Support Vector Machines (SVM)</a></div>
			  <div id="tab_space_lateral"><a href="#sub_6" class="lnk_text">Soft Independent Modeling of Class Analogy (SIMCA)</a></div>			
			  <div id="tab_space_lateral"><a href="#sub_7" class="lnk_text">Unequal class models (UNEQ)</a></div>
			  <div id="tab_space_lateral"><a href="#sub_8" class="lnk_text">Backpropagation Neural Networks (BPNN)</a></div>								    
	   	</div><BR>
<a name="sub_1"></a>
	          <BR>
		        
		        <span class="title_paragraph">Validation procedures </span><BR>
	          <BR>
	          For all classification methods, <strong>cross validation</strong> can be performed with venetian blinds or contiguous blocks (cross-validation type). Regarding venetian blinds, with 3 cross-validation groups the split of the first group in venetian blinds will be [t,0,0,t,0,0,....,t,0,0], while the second one will be [0,t,0,0,t,0,....,0,t,0], and so on, where t are the samples included in the cross-validation groups. On the other hand, the split of the first group with contiguous blocks will be [t,t,t,t,0,0,....,0,0,0] and so on. If cross-validation is performed, the number of cross-validation groups must be defined. Moreover, <strong>bootstrap</strong> with resampling or validation based on random sampling (<strong>montecarlo</strong>) of 20% of samples can be calculated. If bootstrap or montecarlo validation are selected, the number of iterations must be defined.<BR>
	          <BR>
		      [<a href="#top" class="lnk_text">-> top</a>]
	          <BR>
              <BR>
<a name="sub_1a"></a>
	          <BR>
		        
		        <span class="title_paragraph">Discriminant Analysis (DA)</span><BR>
	          <BR>
	          In order to calculate classification models based on <a href="theory.htm" class="lnk_text">Discriminant Analysis (DA)</a>, select &quot;calculate-&gt;Discriminant Analysis-&gt;fit DA&quot;. 
	          The form to select the DA options will appear. Here you can select the type of DA (Linear or Quadratic) and the type of  <a href="#sub_1" class="lnk_text">validation</a>.              <BR>

              <strong>Multinormal distribution</strong> for data can be analysed by clicking &quot;calculate-&gt;Discriminant Analysis-&gt;check multinormality&quot;. In this case, a new figure will appear with results of the multinormality test based on squared generalized distance and chi-square percentiles. Data can be assumed to be multinormally distributed if: 1. the plot of the ordered squared distances and the chi-square percentiles is nearly linear; 2. roughly half of the distances are less then or equal to chi-square percentile of 0.5 [Johnson,R.A. Wichern,D.W., Applied Multivariate Statistical Analysis, 2008].<BR>
	          <BR>
		      [<a href="#top" class="lnk_text">-> top</a>]
	          <BR>
	          <BR> 

	          <a name="sub_2" id="sub_2"></a>
	          <BR>
		        
	          <span class="title_paragraph">Discriminant Analysis coupled with Principal Component Analysis (PCA-DA)</span>
	          <BR>
	          <BR>
	          Discriminant Analysis can be calculated on the scores produced by Principal Component Analysis. In order to evaluate the optimal number of components to be retained, select calculate-&gt;Discriminant Analysis-&gt;optimal components for PCA-DA&quot;. The form for settings PCA-DA options will appear. Here you can select the data scaling, the type of DA model to be calculated (Linear or Quadratic), and the type of <a href="#sub_1" class="lnk_text">cross validation</a>. The cross validation procedure for selecting the optimal components for PCA-DA will produce a plot of the error rate in classification as a function of the number of components retained in the model. See the <a href="example.htm" class="lnk_text">example</a> provided in this help to better understand. Finally, in order to calculate the PCA-DA model, select &quot;calculate-&gt;Discriminant Analysis-&gt;PCA-DA&quot;. The corresponding setting form will appear. Here you can select the number of components to be retained in the model, data scaling,  type of DA model to be calculated (Linear or Quadratic), and  type of  <a href="#sub_1" class="lnk_text">validation</a>.<BR>
	          <BR>
	          [<a href="#top" class="lnk_text">-> top</a>] <BR>
              <BR>
              <a name="sub_3" id="sub_3"></a> <BR>
              <span class="title_paragraph">Partial Least Square - Discriminant Analysis (PLSDA)</span><BR>
              <BR>
              In order to evaluate the optimal number of latent variables to be retained for <a href="theory.htm" class="lnk_text">Partial Least Square - Discriminant Analysis (PLSDA)</a>, select &quot;calculate-&gt;Partial Least Squares DA-&gt;optimal components for PLSDA&quot;. The form for settings PLSDA options will appear. Here you can select the data scaling,  the type of assignation criterion (e.g. how each sample is assigned to classes, see the <a href="theory.htm" class="lnk_text">theory</a> section for further information) and the type of <a href="#sub_1" class="lnk_text">cross validation</a>. The cross validation procedure for selecting the optimal components for PLSDA will produce a plot of the number of components retained in the model versus the error rate in classification. See the <a href="example.htm" class="lnk_text">example</a> provided in this help to better understand. Finally, in order to calculate the PLSDA model, select &quot;calculate-&gt;Partial Least Squares DA-&gt;fit PLSDA&quot;. The corresponding setting form will appear. Here you can select the number of components to be retained in the model, data scaling,  type of assignation criterion  (see the <a href="theory.htm" class="lnk_text">theory</a> section for further information), and type of  <a href="#sub_1" class="lnk_text">validation</a>.<BR>
<BR>
[<a href="#top" class="lnk_text">-> top</a>] <BR>
<BR>
<a name="sub_4" id="sub_4"></a> <BR>
<span class="title_paragraph">Classification Trees (CART)</span><BR>
<BR>
In order to calculate classification models based on <a href="theory.htm" class="lnk_text">Classification trees (CART)</a>, select &quot;calculate-&gt;CART&quot;. The form for settings CART options will appear. Here you can select  the type of <a href="#sub_1" class="lnk_text"> validation</a> you want to apply.<BR>
<BR>
[<a href="#top" class="lnk_text">-> top</a>] <BR>
<BR>
                <a name="sub_5" id="sub_5"></a> <BR>
                <span class="title_paragraph">K-Nearest Neighbors (kNN)</span><BR>
                <BR>
In order to evaluate the optimal number of neighbours (k) for <a href="theory.htm" class="lnk_text">K-Nearest Neighbors (kNN)</a>, select &quot;calculate-&gt;K-Nearest Neighbors-&gt;optimal k for kNN &quot;. The form for settings kNN options will appear. Here you can select the data scaling, the type of distance and the type of <a href="#sub_1" class="lnk_text"> validation</a>. The cross validation procedure for selecting the optimal k will produce a plot of the k values versus the error rate in classification. See the <a href="example.htm" class="lnk_text">example</a> provided in this help to better understand. Finally, in order to calculate the kNN model, select &quot;calculate-&gt;-&gt;K-Nearest Neighbors-&gt;fit kNN&quot;. The corresponding setting form will appear. Here you can select the number of neighbours (k), data scaling, type of distance, and type of  <a href="#sub_1" class="lnk_text">validation</a>.<BR>
<BR>
[<a href="#top" class="lnk_text">-> top</a>] <BR>
<BR>
<a name="sub_5a" id="sub_5a"></a> <BR>
<span class="title_paragraph">Potential Functions (Kernel Density Estimators)</span><BR>
<BR>
When dealing with <a href="theory.htm" class="lnk_text">Potential Function</a>, in order to evaluate the optimal smoothing parameters (for a given target class), select &quot;calculate-&gt;Potential functions-&gt;optimal smoothing for PF&quot;. The form for settings Potential Functions options will appear. Here you can select the target class, data scaling, the percentile to define the class boundary and the type of <a href="#sub_1" class="lnk_text"> validation</a>. The cross validation procedure for selecting the optimal smoothing parameter will produce a plot of the smoothing values  versus the class error rate, specificity and sensitivity.  Finally, in order to calculate Potential Functions, select &quot;calculate-&gt;Potential functions-&gt;PF&quot;. The corresponding setting form will appear. Here you can select the target class and its smoothing parameter, data scaling, and the percentile to define the class boundary, as well as the type of  <a href="#sub_1" class="lnk_text">validation</a>. Potential Functions can also be calculated on scores obtained by means of Principal Components Analysis. In this case, the number of PCs to be used can be selected in the setting form; the &quot;automatic&quot; option will selects  PCs with  eigenvalue higher than the average eigenvalue. Note that the PCA model is calculated only on the samples of the target class. Sampels of other classes will thus be projected into the PCA class model. <BR>
<BR>
[<a href="#top" class="lnk_text">-> top</a>] <BR>
<BR>
<a name="sub_5b" id="sub_5b"></a> <BR>
<span class="title_paragraph">Support Vector Machines  (SVM)</span><BR>
<BR>
When dealing with <a href="theory.htm" class="lnk_text">Support Vector Machines</a>, in order to evaluate the optimal cost value (as well as the optimal kernel parameter when using polynomial or RBF kernels), select &quot;calculate-&gt;SVM-&gt;optimal parameters for SVM&quot;. The form for settings SVM options will appear. Here you can select the data scaling, the type of kernel and the type of <a href="#sub_1" class="lnk_text"> validation</a>. The cross validation procedure for selecting the optimal smoothing parameter will produce a plot of the cost values versus the error rate in classification (as well as the average number of support vectors), when dealing with a linear kernel; when using RBF or polynomial kernels, it will produce a surface plot of the cost values and kernel parameters values versus the error rate in classification (as well as the average number of support vectors). Finally, in order to calculate the SVM model, select &quot;calculate-&gt;SVM-&gt;fit SVM&quot;. The corresponding setting form will appear. Here you can select the kernel type, cost value, kernel parameter (if dealing with RBF or polynomial kernels), data scaling, and type of  <a href="#sub_1" class="lnk_text">validation</a>. SVM can also be calculated on scores obtained by means of Principal Components Analysis. In this case, the number of PCs to be used can be selected in the setting form; the &quot;automatic&quot; option will selects PCs with eigenvalue higher than the average eigenvalue. <BR>
<BR>
[<a href="#top" class="lnk_text">-> top</a>] <BR>
<BR>

<a name="sub_6" id="sub_6"></a> <BR>
<span class="title_paragraph">Soft Independent Modeling of Class Analogy (SIMCA)</span><BR>
<BR>
When dealing with <a href="theory.htm" class="lnk_text">SIMCA</a>, in order to evaluate the optimal number of components to be retained for the PCA target class model, select &quot;calculate-&gt;SIMCA-&gt;optimal components for SIMCA &quot;. The form for settings SIMCA options will appear. Here you can select the target class, data scaling and the type of <a href="#sub_1" class="lnk_text"> validation</a>. The cross validation procedure for selecting the optimal components for SIMCA will produce a plot of the number of components retained in the PCA class model versus the class error rate, specificity and sensitivity.  Finally, in order to calculate the SIMCA model, select &quot;calculate-&gt;SIMCA-&gt;fit SIMCA&quot;. The corresponding setting form will appear. Here you can select the target class, the number of components to be retained, data scaling, and type of  <a href="#sub_1" class="lnk_text">validation</a>.<BR>
<BR>
[<a href="#top" class="lnk_text">-> top</a>] <BR>
<BR>
<a name="sub_7" id="sub_7"></a> <BR>
<span class="title_paragraph">Unequal class models (UNEQ)</span><BR>
<BR>
When dealing with <a href="theory.htm" class="lnk_text">UNEQ</a>, in order to evaluate the optimal number of components to be retained for the PCA target class model, select &quot;calculate-&gt;UNEQ-&gt;optimal components for UNEQ&quot;. The form for settings UNEQ options will appear. Here you can select the target class, data scaling and the type of <a href="#sub_1" class="lnk_text"> validation</a>. The cross validation procedure for selecting the optimal components for UNEQ will produce a plot of the number of components retained in the PCA class model versus the class error rate, specificity and sensitivity. Finally, in order to calculate the UNEQ model, select &quot;calculate-&gt;UNEQ-&gt;fit UNEQ&quot;. The corresponding setting form will appear. Here you can select the tagret class, number of components to be retained, data scaling, and type of <a href="#sub_1" class="lnk_text">validation</a>.<BR>
<BR>
[<a href="#top" class="lnk_text">-> top</a>] <BR>
<BR>
<a name="sub_8" id="sub_8"></a> <BR>
<span class="title_paragraph">Backpropagation Neural Networks (BPNN)</span><BR>
<BR>
In order to calculate  Backpropagation Neural Networks, select &quot;calculate-&gt;Backpropagatipn NN&quot;. The corresponding setting form will appear. Here you can select the number of hidden layers, the number of neurons for hidden layers (for more flexible options model your data through the <a href="routines.htm" class="lnk_text">MATLAB routines</a>), learning rate, alpha (momentum term), number of iterations and type of <a href="#sub_1" class="lnk_text">validation</a>.<BR>
<BR>
[<a href="#top" class="lnk_text">-> top</a>] <BR>
<BR>&nbsp;
                <center><div class="text"></div>
              </center>
          </div></td>
  		</tr>
	  </table>

    </div>

    <div id="footer">
		<iframe src="footer.htm" width="700" height="13" scrolling="no" frameborder="0">
  			no i_frames allowed :: change browser
	  	</iframe>
	</div>
</div>
</body>
</html>